{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 收敛数列的性质（CS/AI 专项笔记·精修版）\n",
    "## 1. 核心性质精确定义（基于数学分析严格表述）\n",
    "收敛数列的性质是数列极限理论的核心内容，是判定数列收敛、计算极限值、分析数列行为的基础，同时也是CS/AI领域中迭代算法稳定性、数值计算可靠性的理论支撑。以下性质均基于**数列收敛的 $\\varepsilon-N$ 定义**推导，即若 $\\lim_{n \\to \\infty} x_n = a$，$\\lim_{n \\to \\infty} y_n = b$（$a,b$ 为有限常数），则数列 $\\{x_n\\}, \\{y_n\\}$ 满足以下性质。\n",
    "\n",
    "## 2. 八大核心性质（定义+证明+CS/AI应用）\n",
    "### 2.1 唯一性\n",
    "#### 2.1.1 严格定义\n",
    "若数列 $\\{x_n\\}$ 收敛，则其极限**唯一**，即不存在两个不同的常数 $a,b$ 同时作为 $\\{x_n\\}$ 的极限。\n",
    "\n",
    "#### 2.1.2 数学证明（反证法）\n",
    "1.  **假设**：设 $\\{x_n\\}$ 同时收敛于 $a$ 和 $b$，且 $a \\neq b$；\n",
    "2.  **构造 $\\varepsilon$**：取 $\\varepsilon = \\frac{|a - b|}{2} > 0$（$\\varepsilon$ 为 $a,b$ 距离的一半，是证明的关键构造）；\n",
    "3.  **应用极限定义**：\n",
    "    - 由 $\\lim_{n \\to \\infty} x_n = a$，存在 $N_1 \\in \\mathbb{N}^+$，当 $n > N_1$ 时，$|x_n - a| < \\varepsilon$；\n",
    "    - 由 $\\lim_{n \\to \\infty} x_n = b$，存在 $N_2 \\in \\mathbb{N}^+$，当 $n > N_2$ 时，$|x_n - b| < \\varepsilon$；\n",
    "4.  **导出矛盾**：取 $N = \\max(N_1, N_2)$，当 $n > N$ 时，由三角不等式得：\n",
    "    $$|a - b| = |(a - x_n) + (x_n - b)| \\leq |x_n - a| + |x_n - b| < \\varepsilon + \\varepsilon = |a - b|$$\n",
    "    显然 $|a - b| < |a - b|$ 矛盾，故假设不成立，极限唯一。\n",
    "\n",
    "#### 2.1.3 CS/AI 核心应用\n",
    "- **算法收敛稳定性**：梯度下降、牛顿法等优化算法的参数序列 $\\{\\theta_n\\}$ 若收敛，必趋于唯一最优解，避免模型参数在多个值之间波动；\n",
    "- **模型结果一致性**：深度学习中损失函数的迭代序列 $\\{L_n\\}$ 收敛到唯一最小值，保证不同训练轮次最终得到一致的模型性能。\n",
    "\n",
    "### 2.2 有界性\n",
    "#### 2.2.1 严格定义\n",
    "若数列 $\\{x_n\\}$ 收敛，则 $\\{x_n\\}$ 是**有界数列**，即存在正数 $M$，使得对所有正整数 $n$，都有 $|x_n| \\leq M$。\n",
    "\n",
    "#### 2.2.2 数学证明\n",
    "1.  由 $\\lim_{n \\to \\infty} x_n = a$，取 $\\varepsilon = 1$（任意固定正数均可），存在 $N \\in \\mathbb{N}^+$，当 $n > N$ 时，$|x_n - a| < 1$；\n",
    "2.  由三角不等式，$|x_n| = |(x_n - a) + a| \\leq |x_n - a| + |a| < 1 + |a|$；\n",
    "3.  取 $M = \\max\\{|x_1|, |x_2|, \\dots, |x_N|, 1 + |a|\\}$，则对所有 $n \\in \\mathbb{N}^+$，$|x_n| \\leq M$，故 $\\{x_n\\}$ 有界。\n",
    "\n",
    "#### 2.2.3 CS/AI 核心应用\n",
    "- **数值计算防溢出**：神经网络训练中，权重参数序列 $\\{w_n\\}$、梯度序列 $\\{g_n\\}$ 因收敛而有界，避免出现梯度爆炸导致的数值溢出；\n",
    "- **内存资源优化**：有界数列的项取值范围可控，在存储迭代中间结果时，可提前规划内存空间，提升程序运行效率。\n",
    "\n",
    "### 2.3 保号性\n",
    "#### 2.3.1 严格定义\n",
    "若 $\\lim_{n \\to \\infty} x_n = a > 0$（或 $a < 0$），则存在正整数 $N$，当 $n > N$ 时，$x_n > 0$（或 $x_n < 0$）。**推论**：若 $\\lim_{n \\to \\infty} x_n = a > 0$，则存在 $N$，当 $n > N$ 时，$x_n > \\frac{a}{2}$（可指定具体正下界）。\n",
    "\n",
    "#### 2.3.2 数学证明（以 $a > 0$ 为例）\n",
    "1.  由 $\\lim_{n \\to \\infty} x_n = a$，取 $\\varepsilon = \\frac{a}{2} > 0$，存在 $N \\in \\mathbb{N}^+$，当 $n > N$ 时，$|x_n - a| < \\frac{a}{2}$；\n",
    "2.  展开绝对值不等式：$-\\frac{a}{2} < x_n - a < \\frac{a}{2}$，移项得 $x_n > a - \\frac{a}{2} = \\frac{a}{2} > 0$；\n",
    "3.  故当 $n > N$ 时，$x_n > 0$，保号性成立。\n",
    "\n",
    "#### 2.3.3 CS/AI 核心应用\n",
    "- **优化方向判定**：若梯度序列 $\\{g_n\\}$ 收敛于 $a > 0$，则后期迭代中梯度恒正，可确定参数需持续减小，避免方向误判；\n",
    "- **概率值有效性保障**：生成模型中概率序列 $\\{p_n\\}$ 收敛于 $a > 0$，保号性确保后期迭代的概率值均为正，符合概率分布的基本要求。\n",
    "\n",
    "### 2.4 保不等式性\n",
    "#### 2.4.1 严格定义\n",
    "若存在正整数 $N_0$，当 $n > N_0$ 时，$x_n \\leq y_n$，且 $\\lim_{n \\to \\infty} x_n = a$，$\\lim_{n \\to \\infty} y_n = b$，则 $a \\leq b$。**注意**：即使 $x_n < y_n$ 对所有 $n$ 成立，也只能推出 $a \\leq b$，而非 $a < b$（如 $x_n = \\frac{1}{n}$，$y_n = \\frac{2}{n}$，$x_n < y_n$，但极限均为 0）。\n",
    "\n",
    "#### 2.4.2 数学证明\n",
    "1.  假设 $a > b$，取 $\\varepsilon = \\frac{a - b}{2} > 0$；\n",
    "2.  存在 $N_1$，当 $n > N_1$ 时，$x_n > a - \\varepsilon = \\frac{a + b}{2}$；存在 $N_2$，当 $n > N_2$ 时，$y_n < b + \\varepsilon = \\frac{a + b}{2}$；\n",
    "3.  取 $N = \\max(N_0, N_1, N_2)$，当 $n > N$ 时，$x_n > \\frac{a + b}{2} > y_n$，与 $x_n \\leq y_n$ 矛盾，故 $a \\leq b$。\n",
    "\n",
    "#### 2.4.3 CS/AI 核心应用\n",
    "- **模型性能对比**：两个模型的验证集损失序列满足 $L_1(n) \\leq L_2(n)$ 且均收敛，则最终损失值 $L_1^* \\leq L_2^*$，可直接判定模型 1 更优；\n",
    "- **约束条件传递**：在带约束的优化问题中，参数序列满足的不等式约束，可通过保不等式性传递到极限值，确保最优解满足约束条件。\n",
    "\n",
    "### 2.5 迫敛性（夹逼准则）\n",
    "#### 2.5.1 严格定义\n",
    "若存在正整数 $N_0$，当 $n > N_0$ 时，$x_n \\leq y_n \\leq z_n$，且 $\\lim_{n \\to \\infty} x_n = \\lim_{n \\to \\infty} z_n = a$，则 $\\lim_{n \\to \\infty} y_n = a$。该性质是**间接求极限**的核心工具，适用于通项复杂但可构造界数列的场景。\n",
    "\n",
    "#### 2.5.2 数学证明\n",
    "1.  由 $\\lim_{n \\to \\infty} x_n = a$ 和 $\\lim_{n \\to \\infty} z_n = a$，对任意 $\\varepsilon > 0$，存在 $N_1, N_2$：\n",
    "    - 当 $n > N_1$ 时，$a - \\varepsilon < x_n < a + \\varepsilon$；\n",
    "    - 当 $n > N_2$ 时，$a - \\varepsilon < z_n < a + \\varepsilon$；\n",
    "2.  取 $N = \\max(N_0, N_1, N_2)$，当 $n > N$ 时，$a - \\varepsilon < x_n \\leq y_n \\leq z_n < a + \\varepsilon$，即 $|y_n - a| < \\varepsilon$；\n",
    "3.  故 $\\lim_{n \\to \\infty} y_n = a$。\n",
    "\n",
    "#### 2.5.3 CS/AI 核心应用\n",
    "- **复杂损失函数极限计算**：深度学习中复合损失函数的迭代序列，可通过构造简单的上界、下界损失序列，利用夹逼准则快速判定收敛值；\n",
    "- **数据噪声平滑**：含噪声的传感器数据序列，可通过滑动窗口构造上下界序列，迫敛到真实信号值，实现噪声去除。\n",
    "\n",
    "### 2.6 四则运算法则\n",
    "#### 2.6.1 严格定义\n",
    "收敛数列的和、差、积、商（分母极限非零）仍收敛，且极限满足以下运算规则：\n",
    "1. $\\lim_{n \\to \\infty} (x_n \\pm y_n) = a \\pm b$；\n",
    "2. $\\lim_{n \\to \\infty} (x_n \\cdot y_n) = a \\cdot b$（推论：$\\lim_{n \\to \\infty} (k \\cdot x_n) = k \\cdot a$，$k$ 为常数）；\n",
    "3. $\\lim_{n \\to \\infty} \\frac{x_n}{y_n} = \\frac{a}{b}$（前提：$b \\neq 0$）。\n",
    "\n",
    "#### 2.6.2 数学证明（以乘法法则为例）\n",
    "1.  由收敛数列有界性，存在 $M > 0$，使得 $|x_n| \\leq M$ 对所有 $n$ 成立；\n",
    "2.  对任意 $\\varepsilon > 0$，存在 $N_1, N_2$：\n",
    "    - 当 $n > N_1$ 时，$|x_n - a| < \\frac{\\varepsilon}{2(|b| + 1)}$；\n",
    "    - 当 $n > N_2$ 时，$|y_n - b| < \\frac{\\varepsilon}{2M}$；\n",
    "3.  取 $N = \\max(N_1, N_2)$，当 $n > N$ 时：\n",
    "    $$|x_n y_n - ab| = |x_n(y_n - b) + b(x_n - a)| \\leq |x_n||y_n - b| + |b||x_n - a| < M \\cdot \\frac{\\varepsilon}{2M} + |b| \\cdot \\frac{\\varepsilon}{2(|b| + 1)} < \\varepsilon$$\n",
    "    故 $\\lim_{n \\to \\infty} (x_n \\cdot y_n) = a \\cdot b$。\n",
    "\n",
    "#### 2.6.3 CS/AI 核心应用\n",
    "- **复合模型损失计算**：多任务学习中，总损失是多个子损失的加权和（如 $L = \\alpha L_1 + \\beta L_2$），利用四则运算法则可直接推导总损失的收敛值；\n",
    "- **参数更新公式推导**：梯度下降中参数更新序列 $\\theta_{n+1} = \\theta_n - \\eta g_n$，可通过和差法则分析参数序列的收敛性。\n",
    "\n",
    "### 2.7 子数列收敛性\n",
    "#### 2.7.1 严格定义\n",
    "若数列 $\\{x_n\\}$ 收敛于 $a$，则其**任意子数列** $\\{x_{n_k}\\}$（$n_1 < n_2 < \\dots < n_k < \\dots$）也收敛于 $a$。**逆否命题**：若数列存在两个收敛于不同极限的子数列，则原数列发散（如 $x_n = (-1)^n$，子数列 $\\{x_{2k}\\}$ 收敛于 1，$\\{x_{2k-1}\\}$ 收敛于 -1，故原数列发散）。\n",
    "\n",
    "#### 2.7.2 数学证明\n",
    "1.  由 $\\lim_{n \\to \\infty} x_n = a$，对任意 $\\varepsilon > 0$，存在 $N \\in \\mathbb{N}^+$，当 $n > N$ 时，$|x_n - a| < \\varepsilon$；\n",
    "2.  因 $\\{x_{n_k}\\}$ 是子数列，$n_k \\geq k$，故当 $k > N$ 时，$n_k > N$；\n",
    "3.  此时 $|x_{n_k} - a| < \\varepsilon$，故 $\\lim_{k \\to \\infty} x_{n_k} = a$。\n",
    "\n",
    "#### 2.7.3 CS/AI 核心应用\n",
    "- **算法早停策略设计**：训练模型时，取损失序列的子数列（如每 10 轮的损失值），若子数列收敛，则可判定原损失序列收敛，提前停止训练；\n",
    "- **并行计算结果验证**：分布式训练中，不同节点的参数更新序列可视为原序列的子数列，子数列均收敛于同一值，验证并行计算的一致性。\n",
    "\n",
    "### 2.8 柯西收敛准则（充要条件）\n",
    "#### 2.8.1 严格定义\n",
    "数列 $\\{x_n\\}$ 收敛 $\\iff$ 对任意 $\\varepsilon > 0$，存在正整数 $N$，当 $m, n > N$ 时，$|x_m - x_n| < \\varepsilon$。该准则不依赖极限值，仅通过数列**自身的内在一致性**判定收敛，是分析未知极限数列的核心工具。\n",
    "\n",
    "#### 2.8.2 核心价值证明（必要性）\n",
    "1.  若 $\\lim_{n \\to \\infty} x_n = a$，对任意 $\\varepsilon > 0$，存在 $N$，当 $m, n > N$ 时，$|x_m - a| < \\frac{\\varepsilon}{2}$，$|x_n - a| < \\frac{\\varepsilon}{2}$；\n",
    "2.  由三角不等式，$|x_m - x_n| \\leq |x_m - a| + |x_n - a| < \\varepsilon$，故必要性成立。\n",
    "\n",
    "#### 2.8.3 CS/AI 核心应用\n",
    "- **复杂模型收敛性判定**：神经网络的参数序列 $\\{\\theta_n\\}$ 无法预先知道极限值，通过柯西准则验证 $|\\theta_m - \\theta_n| < \\varepsilon$，即可判定收敛；\n",
    "- **数值迭代精度控制**：牛顿法、共轭梯度法等迭代算法中，当相邻两次迭代结果的差值小于阈值时，停止迭代，本质是柯西准则的工程应用。\n",
    "\n",
    "### 2.9 致密性定理（Bolzano-Weierstrass 定理）\n",
    "#### 2.9.1 严格定义\n",
    "有界数列必有收敛子数列。该性质是连接“有界性”和“收敛性”的桥梁，即使原数列发散，只要有界，就存在收敛的子数列，是分析发散数列局部行为的重要工具。\n",
    "\n",
    "#### 2.9.2 数学意义\n",
    "致密性定理是实数系基本定理之一，保证了有界数列的“局部稳定性”。对于AI中振荡但有界的序列（如GAN的损失序列），可通过提取收敛子数列分析模型的局部收敛趋势。\n",
    "\n",
    "#### 2.9.3 CS/AI 核心应用\n",
    "- **GAN模型训练分析**：GAN的生成器损失序列可能振荡发散，但因损失值非负有界，存在收敛子数列，可通过该子数列优化模型参数；\n",
    "- **异常数据检测**：时序数据中，剔除异常值后的序列通常有界，利用致密性定理提取收敛子数列，可实现正常数据的趋势预测。\n",
    "\n",
    "## 3. 性质对比与易错点辨析\n",
    "```html\n",
    "<table style=\"width:100%; border-collapse: collapse; margin: 16px 0; font-size: 14px;\">\n",
    "  <thead>\n",
    "    <tr style=\"background-color: #f5f5f5;\">\n",
    "      <th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; font-weight: 600;\">性质</th>\n",
    "      <th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; font-weight: 600;\">核心易错点</th>\n",
    "      <th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; font-weight: 600;\">CS/AI 避坑指南</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">唯一性</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">误认为“数列有多个极限”</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">训练中参数波动不代表多极限，可能是未收敛，需延长迭代次数</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #fafafa;\">\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">有界性</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">混淆“有界”与“收敛”，认为有界数列必收敛</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">有界是收敛的必要条件而非充分条件，需结合单调性等进一步判定</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">保不等式性</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">由 $x_n < y_n$ 推出 $a < b$</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">模型性能对比时，即使 $L_1(n) < L_2(n)$，也可能最终损失相等</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #fafafa;\">\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">夹逼准则</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">上下界数列极限不相等时误用准则</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">构造界数列时，需确保上下界极限相同，否则准则失效</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "```\n",
    "\n",
    "## 4. 伪代码（性质的工程实现与验证）\n",
    "以下代码针对核心性质设计验证工具，可直接用于AI迭代序列的收敛性分析（如损失序列、参数序列）。\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def verify_convergence_properties(seq, limit=None, eps=1e-6):\n",
    "    \"\"\"\n",
    "    验证收敛数列的核心性质（有界性、保号性、子数列收敛性）\n",
    "    参数：\n",
    "        seq: 输入数列（list或numpy数组）\n",
    "        limit: 数列的理论极限值（可选）\n",
    "        eps: 收敛阈值\n",
    "    返回：\n",
    "        dict: 各性质的验证结果\n",
    "    \"\"\"\n",
    "    seq = np.array(seq, dtype=float)\n",
    "    n = len(seq)\n",
    "    result = {}\n",
    "\n",
    "    # 1. 验证有界性\n",
    "    upper_bound = np.max(np.abs(seq))\n",
    "    result[\"有界性\"] = {\"是否有界\": True, \"界值\": upper_bound}\n",
    "\n",
    "    # 2. 验证保号性（若极限已知且非零）\n",
    "    if limit is not None and limit != 0:\n",
    "        sign = \"正\" if limit > 0 else \"负\"\n",
    "        # 找到序列中最后满足|x_n - limit| < eps的起始索引N\n",
    "        N = np.argmax(np.abs(seq - limit) < eps)\n",
    "        if N < n - 1:\n",
    "            late_terms = seq[N+1:]\n",
    "            all_positive = np.all(late_terms > 0) if limit > 0 else np.all(late_terms < 0)\n",
    "            result[\"保号性\"] = {\"是否满足\": all_positive, \"起始项索引\": N+1}\n",
    "        else:\n",
    "            result[\"保号性\"] = {\"是否满足\": False, \"原因\": \"序列未收敛到指定极限\"}\n",
    "\n",
    "    # 3. 验证子数列收敛性（取偶数项子数列）\n",
    "    even_seq = seq[::2]  # 偶数项子数列\n",
    "    if limit is not None:\n",
    "        even_conv = np.max(np.abs(even_seq - limit)) < eps\n",
    "        result[\"子数列收敛性\"] = {\"偶数项子数列是否收敛到极限\": even_conv}\n",
    "\n",
    "    # 4. 验证柯西条件\n",
    "    cauchy_satisfied = True\n",
    "    for m in range(n//2, n):\n",
    "        for k in range(m+1, n):\n",
    "            if abs(seq[m] - seq[k]) >= eps:\n",
    "                cauchy_satisfied = False\n",
    "                break\n",
    "        if not cauchy_satisfied:\n",
    "            break\n",
    "    result[\"柯西条件\"] = {\"是否满足\": cauchy_satisfied}\n",
    "\n",
    "    return result\n",
    "\n",
    "# 示例：验证数列 x_n = (2n+1)/n 的收敛性质（理论极限=2）\n",
    "n = np.arange(1, 1001)\n",
    "seq = (2 * n + 1) / n\n",
    "properties = verify_convergence_properties(seq, limit=2, eps=1e-6)\n",
    "\n",
    "for prop_name, prop_val in properties.items():\n",
    "    print(f\"{prop_name}: {prop_val}\")\n",
    "```\n",
    "\n",
    "## 5. 拓展与联系（CS/AI 知识体系定位）\n",
    "### 5.1 前置知识关联\n",
    "- 数列极限的 $\\varepsilon-N$ 定义是所有性质的理论基础；\n",
    "- 实数的基本性质（三角不等式、确界原理）是性质证明的核心工具；\n",
    "- 不等式求解、数学归纳法是推导过程中常用的数学技巧。\n",
    "\n",
    "### 5.2 后续知识延伸\n",
    "- **函数极限**：收敛数列的性质可完全推广到函数极限（如函数极限的唯一性、保号性等）；\n",
    "- **微积分**：定积分的定义依赖黎曼和数列的极限，其存在性可通过数列的收敛性质判定；\n",
    "- **AI 优化理论**：凸优化中梯度下降序列的收敛性分析，核心是单调有界准则和柯西收敛准则的应用；\n",
    "- **数值分析**：迭代法（雅可比迭代、高斯-赛德尔迭代）的收敛性判定，依赖数列的保号性、有界性等性质。\n",
    "\n",
    "### 5.3 工程实践价值\n",
    "收敛数列的性质是连接“纯数学理论”与“AI工程实现”的桥梁，其价值体现在：\n",
    "1. **算法设计**：指导迭代算法的参数设置（如学习率、迭代次数）；\n",
    "2. **性能保障**：确保模型训练过程稳定，避免数值异常；\n",
    "3. **精度控制**：通过柯西条件、夹逼准则等设定迭代停止阈值，平衡精度与效率。\n",
    "\n",
    "## 6. 学习建议（CS/AI 方向专属）\n",
    "1.  **优先级掌握**：唯一性、有界性、四则运算法则是基础，夹逼准则、柯西收敛准则是AI中高频应用的核心工具；\n",
    "2.  **证明逻辑拆解**：所有性质的证明均遵循“$\\varepsilon$ 任意给定→找到 $N$→验证不等式”的逻辑，重点练习“构造 $\\varepsilon$”的技巧；\n",
    "3.  **工程化落地**：结合模型训练日志，提取损失序列、参数序列，用上述代码验证性质，直观理解理论在实践中的体现；\n",
    "4.  **避坑重点**：区分“必要条件”与“充分条件”（如有界是收敛的必要条件，单调有界是收敛的充分条件），避免在算法分析中误用。\n",
    "\n",
    "是否需要我针对某一性质（如夹逼准则、柯西收敛准则）在具体AI算法（如梯度下降、GAN）中的应用，提供更详细的案例推导？"
   ],
   "id": "ee8f56bc8a39cb64"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
