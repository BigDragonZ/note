{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 不定积分的概念和性质（CS/AI 专项笔记·精研版）\n",
    "## 前言\n",
    "不定积分是微积分中**导数逆运算的核心理论**，其本质是通过已知函数（被积函数）寻找一个“函数族”，使得该函数族的导数均等于被积函数。在AI领域，不定积分的概念和性质是**概率模型建模（PDF→CDF）、期望与累积奖励计算、积分约束优化**的基础——例如逻辑回归的Sigmoid输出本质是逻辑分布PDF的原函数（CDF），强化学习的累积奖励是瞬时奖励的积分形式，生成模型的概率归一化约束依赖积分的线性性质。本章将聚焦“概念本质+性质应用”，以严格定义为核心，结合AI场景拆解性质的工程价值，适配Jupyter归档与CS/AI理论落地需求。\n",
    "\n",
    "## 1. 不定积分的核心概念（严格定义+AI直观理解）\n",
    "### 1.1 原函数（不定积分的基础）\n",
    "#### 1.1.1 严格数学定义\n",
    "设函数 $f(x)$ 在区间 $I$ 上有定义，若存在函数 $F(x)$，使得对任意 $x \\in I$ 满足：\n",
    "$$\\boxed{F'(x) = f(x) \\quad \\text{或} \\quad dF(x) = f(x)dx}$$\n",
    "则称 $F(x)$ 为 $f(x)$ 在区间 $I$ 上的**一个原函数**。\n",
    "\n",
    "#### 1.1.2 AI直观理解\n",
    "- 原函数是“导数运算的逆映射”：若将导数看作“求变化率”，则原函数看作“还原变化累积”；\n",
    "- 典型场景：\n",
    "  - 概率建模中，若 $f(x)$ 是概率密度函数（PDF，描述瞬时概率密度），则原函数 $F(x)$ 是累积分布函数（CDF，描述概率累积）；\n",
    "  - 强化学习中，若 $r(t)$ 是瞬时奖励函数（描述某时刻奖励），则原函数 $R(t)$ 是累积奖励函数（描述从初始时刻到 $t$ 的奖励总和）。\n",
    "\n",
    "#### 1.1.3 原函数的存在性与唯一性\n",
    "- **存在性**：若 $f(x)$ 在区间 $I$ 上**连续**，则一定存在原函数（AI中常用函数均满足连续性，可默认存在原函数）；\n",
    "- **唯一性**：原函数不唯一！若 $F(x)$ 是 $f(x)$ 的一个原函数，则所有原函数可表示为 $F(x) + C$（$C$ 为任意常数），即原函数族。\n",
    "\n",
    "### 1.2 不定积分（原函数族的统一表示）\n",
    "#### 1.2.1 严格数学定义\n",
    "若 $F(x)$ 是 $f(x)$ 的一个原函数，则 $f(x)$ 的**所有原函数**称为 $f(x)$ 的不定积分，记为：\n",
    "$$\\boxed{\\int f(x)dx = F(x) + C}$$\n",
    "其中：\n",
    "- 符号解析：$\\int$ 为积分号（表示“求原函数”的运算），$f(x)$ 为被积函数，$f(x)dx$ 为被积表达式（体现微分本质），$x$ 为积分变量，$C$ 为**积分常数**（任意常数，是原函数族的核心标志）；\n",
    "- 核心区别：不定积分的结果是**函数族**（含 $C$），而非单个函数，这是与定积分（数值结果）的关键差异。\n",
    "\n",
    "#### 1.2.2 几何意义（AI场景可视化）\n",
    "- 几何本质：不定积分表示一族“平行曲线”，每条曲线在点 $x$ 处的切线斜率均等于被积函数 $f(x)$；\n",
    "- AI场景映射：\n",
    "  - 概率分布中，CDF族（不同参数的同一分布）对应不定积分的函数族，每条曲线的斜率（导数）均为该分布的PDF；\n",
    "  - 强化学习中，不同初始状态的累积奖励曲线族，每条曲线的斜率均为瞬时奖励函数 $r(t)$。\n",
    "\n",
    "#### 1.2.3 物理意义（工程关联）\n",
    "- 物理本质：若 $f(x)$ 表示速度函数（变化率），则不定积分表示位移函数族（位置累积），积分常数 $C$ 对应初始位置；\n",
    "- AI工程映射：若 $f(w)$ 表示模型参数的梯度变化率，则不定积分表示参数更新的累积效果，积分常数 $C$ 对应初始参数值。\n",
    "\n",
    "### 1.3 核心概念的AI高频关联\n",
    "| 概念         | 数学本质                     | AI场景应用                          | 典型示例                          |\n",
    "|--------------|------------------------------|-----------------------------------|-----------------------------------|\n",
    "| 原函数       | 导数的逆映射                 | PDF→CDF、瞬时奖励→累积奖励         | Sigmoid函数是逻辑分布PDF的原函数  |\n",
    "| 不定积分     | 原函数族（含积分常数 $C$）   | 概率分布族、多初始状态奖励累积     | 不同 $\\lambda$ 的指数分布CDF族    |\n",
    "| 积分常数 $C$ | 原函数的偏移量               | 初始状态/参数的影响因子            | CDF中 $C=0$ 确保 $F(-\\infty)=0$   |\n",
    "\n",
    "## 2. 不定积分的核心性质（严格推导+AI价值）\n",
    "不定积分的性质是简化积分计算、验证结果正确性的核心工具，所有性质均由“导数逆运算”推导而来，以下是AI场景中高频使用的4大性质：\n",
    "\n",
    "### 2.1 线性性质（AI中最常用）\n",
    "#### 2.1.1 严格数学表述\n",
    "设 $f(x)$、$g(x)$ 均存在原函数，$\\alpha$、$\\beta$ 为任意常数，则：\n",
    "$$\\boxed{\\int [\\alpha f(x) + \\beta g(x)]dx = \\alpha \\int f(x)dx + \\beta \\int g(x)dx + C}$$\n",
    "- 推论1（齐次性）：$\\int \\alpha f(x)dx = \\alpha \\int f(x)dx + C$（$\\beta=0$ 时）；\n",
    "- 推论2（可加性）：$\\int [f(x) + g(x)]dx = \\int f(x)dx + \\int g(x)dx + C$（$\\alpha=\\beta=1$ 时）。\n",
    "\n",
    "#### 2.1.2 推导逻辑（基于导数线性性质）\n",
    "对等式右侧求导：\n",
    "$$\\frac{d}{dx}\\left[ \\alpha \\int f(x)dx + \\beta \\int g(x)dx \\right] = \\alpha f(x) + \\beta g(x)$$\n",
    "与左侧被积函数一致，故性质成立（积分常数 $C$ 由原函数族特性引入）。\n",
    "\n",
    "#### 2.1.3 AI核心价值\n",
    "- 多任务学习的损失积分：联合损失函数 $L(w) = \\alpha L_1(w) + \\beta L_2(w)$ 的积分约束（如正则化中的积分项），可通过线性性质拆分计算，简化优化；\n",
    "- 混合分布的CDF计算：混合分布的PDF为 $\\sum_{i=1}^n \\alpha_i f_i(x)$（$\\sum \\alpha_i=1$），其CDF可通过线性性质拆分为各分布CDF的加权和，降低计算复杂度。\n",
    "\n",
    "### 2.2 导数与积分的互逆性质（校验核心）\n",
    "#### 2.2.1 严格数学表述\n",
    "1. 积分对导数的逆运算：$\\boxed{\\frac{d}{dx}\\left[ \\int f(x)dx \\right] = f(x)}$；\n",
    "2. 导数对积分的逆运算：$\\boxed{\\int F'(x)dx = F(x) + C}$（或 $\\int dF(x) = F(x) + C$）。\n",
    "\n",
    "#### 2.2.2 推导逻辑\n",
    "- 性质1：设 $\\int f(x)dx = F(x) + C$，则导数为 $F'(x) = f(x)$，与被积函数一致；\n",
    "- 性质2：$F(x)$ 是 $F'(x)$ 的一个原函数，故所有原函数为 $F(x) + C$。\n",
    "\n",
    "#### 2.2.3 AI核心价值\n",
    "- 积分结果的正确性校验：AI工程中，通过求导验证积分结果是否正确（如验证CDF的导数是否为PDF），避免数值计算错误；\n",
    "- 梯度计算的逆操作：强化学习中，若已知累积奖励函数 $R(t)$ 的梯度（瞬时奖励 $r(t)$），可通过积分还原累积奖励函数。\n",
    "\n",
    "### 2.3 积分变量替换性质（换元法基础）\n",
    "#### 2.3.1 严格数学表述\n",
    "若 $x = \\varphi(t)$ 是**单调可导**函数，且 $\\varphi'(t) \\neq 0$，则：\n",
    "$$\\boxed{\\int f(x)dx = \\int f(\\varphi(t)) \\cdot \\varphi'(t)dt + C}$$\n",
    "（其中 $t = \\varphi^{-1}(x)$ 为 $x = \\varphi(t)$ 的反函数）\n",
    "\n",
    "#### 2.3.2 推导逻辑\n",
    "对右侧求导（复合函数求导法则）：\n",
    "$$\\frac{d}{dx}\\left[ \\int f(\\varphi(t)) \\cdot \\varphi'(t)dt \\right] = f(\\varphi(t)) \\cdot \\varphi'(t) \\cdot \\frac{dt}{dx} = f(x) \\cdot \\varphi'(t) \\cdot \\frac{1}{\\varphi'(t)} = f(x)$$\n",
    "与左侧被积函数一致，故性质成立。\n",
    "\n",
    "#### 2.3.1 AI核心价值\n",
    "- 复杂分布的CDF计算：如正态分布PDF的积分（无法用初等函数表示），通过变量替换转化为误差函数，实现数值近似；\n",
    "- 高维积分的降维：深度学习中带约束的高维积分（如变分推断中的KL散度计算），通过变量替换转化为低维积分，降低计算量。\n",
    "\n",
    "### 2.4 积分形式不变性（简化计算）\n",
    "#### 2.4.1 严格数学表述\n",
    "若 $\\int f(u)du = F(u) + C$，则对任意可导函数 $u = \\varphi(x)$，有：\n",
    "$$\\boxed{\\int f(\\varphi(x)) \\cdot \\varphi'(x)dx = F(\\varphi(x)) + C}$$\n",
    "\n",
    "#### 2.4.2 本质解读\n",
    "积分形式与积分变量的“符号无关”，仅依赖“被积函数形式+内层函数的导数”，是第一类换元法（凑微分法）的理论基础。\n",
    "\n",
    "#### 2.4.3 AI核心价值\n",
    "- 激活函数的积分推导：如ReLU函数的积分（用于损失函数设计），通过凑微分法快速计算，无需复杂变量替换；\n",
    "- 强化学习中折扣奖励的积分：$\\int r(\\gamma t) \\cdot \\gamma dt$（$\\gamma$ 为折扣因子），通过形式不变性直接凑微分求解。\n",
    "\n",
    "## 3. 核心概念与性质的AI案例（理论→工程）\n",
    "### 3.1 案例1：原函数与不定积分的概率应用（逻辑回归）\n",
    "#### 问题背景\n",
    "逻辑回归的输出是Sigmoid函数 $\\sigma(x) = \\frac{1}{1 + e^{-x}}$，需验证其为标准逻辑分布PDF的原函数（CDF）。\n",
    "\n",
    "#### 应用过程\n",
    "1. 标准逻辑分布的PDF：$f(t) = \\frac{e^{-t}}{(1 + e^{-t})^2}$；\n",
    "2. 求原函数：$\\int \\frac{e^{-t}}{(1 + e^{-t})^2}dt$，令 $u = 1 + e^{-t}$，则 $du = -e^{-t}dt$，凑微分得：\n",
    "   $$\\int u^{-2} (-du) = - \\int u^{-2}du = u^{-1} + C = \\frac{1}{1 + e^{-t}} + C$$\n",
    "3. 不定积分与CDF：CDF需满足 $F(-\\infty)=0$、$F(+\\infty)=1$，故取 $C=0$，即 $F(t) = \\frac{1}{1 + e^{-t}}$（Sigmoid函数）；\n",
    "4. 验证互逆性质：对 $F(t)$ 求导，$F'(t) = \\frac{e^{-t}}{(1 + e^{-t})^2} = f(t)$，符合原函数定义。\n",
    "\n",
    "#### AI价值\n",
    "揭示了Sigmoid函数的概率本质，为分类模型的概率解释提供理论依据，同时验证了“积分→导数”的互逆性质在工程中的正确性。\n",
    "\n",
    "### 3.2 案例2：线性性质在多任务损失积分中的应用\n",
    "#### 问题背景\n",
    "多任务学习中，联合损失函数为 $L(w) = 0.6L_{cls}(w) + 0.4L_{reg}(w)$，其中 $L_{cls}(w) = w^2$（分类损失），$L_{reg}(w) = e^w$（回归损失），需计算其积分约束项 $\\int L(w)dw$（用于正则化）。\n",
    "\n",
    "#### 应用过程\n",
    "1. 拆分积分（线性性质）：\n",
    "   $$\\int L(w)dw = 0.6\\int w^2 dw + 0.4\\int e^w dw + C$$\n",
    "2. 分别计算积分：\n",
    "   $$\\int w^2 dw = \\frac{1}{3}w^3 + C_1, \\quad \\int e^w dw = e^w + C_2$$\n",
    "3. 合并结果：\n",
    "   $$\\int L(w)dw = 0.6 \\cdot \\frac{1}{3}w^3 + 0.4 \\cdot e^w + C = 0.2w^3 + 0.4e^w + C$$\n",
    "\n",
    "#### AI价值\n",
    "线性性质将复杂的联合损失积分拆分为简单积分的加权和，降低了积分约束优化的计算复杂度，是多任务学习、混合模型等场景的核心计算工具。\n",
    "\n",
    "## 4. 工程实现（Python 概念与性质验证工具）\n",
    "通过Python的`sympy`库验证不定积分的核心概念（原函数、积分常数）与性质（线性、互逆），代码可直接在Jupyter中运行，适配AI场景的理论验证需求。\n",
    "```python\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "\n",
    "# 符号定义\n",
    "x, w, t = sp.Symbol('x', real=True), sp.Symbol('w', real=True), sp.Symbol('t', real=True)\n",
    "C = sp.Symbol('C', constant=True)  # 积分常数\n",
    "\n",
    "def verify_primitive_function(f_expr, F_expr):\n",
    "    \"\"\"\n",
    "    验证F(x)是否为f(x)的原函数（互逆性质）\n",
    "    参数：\n",
    "        f_expr: 被积函数（sympy表达式）\n",
    "        F_expr: 待验证的原函数（sympy表达式）\n",
    "    返回：\n",
    "        is_primitive: 是否为原函数（bool）\n",
    "        derivative: F(x)的导数（sympy表达式）\n",
    "    \"\"\"\n",
    "    derivative = sp.diff(F_expr, x)\n",
    "    is_primitive = sp.simplify(derivative) == sp.simplify(f_expr)\n",
    "    return is_primitive, derivative\n",
    "\n",
    "def verify_linear_property(f1_expr, f2_expr, alpha=0.6, beta=0.4):\n",
    "    \"\"\"\n",
    "    验证不定积分的线性性质\n",
    "    \"\"\"\n",
    "    # 左侧：∫[αf1 + βf2]dx\n",
    "    left = sp.integrate(alpha * f1_expr + beta * f2_expr, x) + C\n",
    "    # 右侧：α∫f1dx + β∫f2dx + C\n",
    "    right = alpha * sp.integrate(f1_expr, x) + beta * sp.integrate(f2_expr, x) + C\n",
    "    # 简化并比较\n",
    "    left_simplified = sp.simplify(left)\n",
    "    right_simplified = sp.simplify(right)\n",
    "    is_equal = left_simplified == right_simplified\n",
    "    return is_equal, left_simplified, right_simplified\n",
    "\n",
    "# ---------------------- 验证原函数与互逆性质（Sigmoid案例） ----------------------\n",
    "# 标准逻辑分布PDF\n",
    "logistic_pdf = sp.exp(-x) / (1 + sp.exp(-x))**2\n",
    "# Sigmoid函数（待验证原函数）\n",
    "sigmoid = 1 / (1 + sp.exp(-x))\n",
    "# 验证\n",
    "is_primitive, deriv = verify_primitive_function(logistic_pdf, sigmoid)\n",
    "print(\"=== 互逆性质验证（Sigmoid案例） ===\")\n",
    "print(f\"F(x) = {sigmoid}\")\n",
    "print(f\"F'(x) = {deriv.simplify()}\")\n",
    "print(f\"F(x)是否为f(x)的原函数：{is_primitive}\")\n",
    "\n",
    "# ---------------------- 验证线性性质（多任务损失案例） ----------------------\n",
    "# 分类损失L_cls(w) = w²，回归损失L_reg(w) = e^w\n",
    "L_cls = w**2\n",
    "L_reg = sp.exp(w)\n",
    "# 验证线性性质\n",
    "is_linear, left, right = verify_linear_property(L_cls, L_reg)\n",
    "print(\"\\n=== 线性性质验证（多任务损失案例） ===\")\n",
    "print(f\"左侧：∫[0.6L_cls + 0.4L_reg]dw = {left}\")\n",
    "print(f\"右侧：0.6∫L_cls dw + 0.4∫L_reg dw = {right}\")\n",
    "print(f\"线性性质是否成立：{is_linear}\")\n",
    "\n",
    "# ---------------------- 验证不定积分的函数族（积分常数C） ----------------------\n",
    "# 计算∫x²dx\n",
    "integral = sp.integrate(x**2, x) + C\n",
    "print(\"\\n=== 不定积分的函数族特性 ===\")\n",
    "print(f\"∫x²dx = {integral}\")\n",
    "# 验证不同C的原函数导数均为x²\n",
    "C1 = 2  # 任意常数1\n",
    "C2 = 5  # 任意常数2\n",
    "F1 = sp.integrate(x**2, x) + C1\n",
    "F2 = sp.integrate(x**2, x) + C2\n",
    "deriv_F1 = sp.diff(F1, x)\n",
    "deriv_F2 = sp.diff(F2, x)\n",
    "print(f\"C={C1}时，F1(x) = {F1}，F1'(x) = {deriv_F1}\")\n",
    "print(f\"C={C2}时，F2(x) = {F2}，F2'(x) = {deriv_F2}\")\n",
    "```\n",
    "\n",
    "## 5. 常见误区与避坑指南（AI工程视角）\n",
    "```html\n",
    "<table style=\"width:100%; border-collapse: collapse; margin: 16px 0; font-size: 14px;\">\n",
    "  <thead>\n",
    "    <tr style=\"background-color: #f5f5f5;\">\n",
    "      <th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; font-weight: 600;\">易错点</th>\n",
    "      <th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; font-weight: 600;\">错误认知</th>\n",
    "      <th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; font-weight: 600;\">正确结论</th>\n",
    "      <th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; font-weight: 600;\">AI领域影响</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">忽略积分常数C</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">不定积分结果是单个函数，无需加C</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">不定积分是原函数族，C不可省略（仅定积分无C），C由初始条件确定（如CDF需F(0)=0）</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">概率分布CDF计算错误（如Sigmoid函数漏加C导致概率范围异常），积分约束优化失效</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #fafafa;\">\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">混淆原函数与不定积分</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">原函数就是不定积分</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">原函数是不定积分的“一个实例”，不定积分是原函数的“全部集合”（含C）</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">多初始状态的累积奖励计算错误，认为所有初始状态的奖励曲线相同</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">线性性质的系数处理错误</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">∫[αf(x)+βg(x)]dx = α∫f(x)dx + β∫g(x)dx（无C）</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">右侧需加一个积分常数C（而非两个），因多个常数的线性组合仍为常数</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">混合分布的CDF计算出现多个常数项，导致概率归一化失败</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #fafafa;\">\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">否定非初等函数的原函数存在性</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">无法用初等函数表示的积分就是“不存在原函数”</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">原函数存在性由连续性保证（AI中常用函数均连续），只是部分原函数无法用初等函数表示（需用特殊函数如误差函数）</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">正态分布CDF计算卡住，无法推进分类模型的概率预测模块开发</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">换元性质忽略微分替换</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">仅替换被积函数中的变量，忽略dx的替换</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">换元必须同时替换变量和微分（x=φ(t)→dx=φ’(t)dt），否则积分变量不一致</td>\n",
    "      <td style=\"padding: 12px; border: 1px solid #ddd;\">高维积分降维计算错误，变分推断中的KL散度估计偏差</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "```\n",
    "\n",
    "## 6. 学习建议（CS/AI 方向专属）\n",
    "1. **锚定“逆运算+函数族”核心**：不定积分的本质是“导数的逆运算”，核心标志是“含积分常数C的函数族”，所有概念和性质均围绕这两点展开，避免孤立记忆；\n",
    "2. **绑定AI场景理解概念**：将“原函数”与“PDF→CDF”“瞬时奖励→累积奖励”强关联，将“积分常数C”与“初始状态/参数”关联，避免抽象化理解；\n",
    "3. **聚焦高频性质的工程应用**：优先掌握线性性质和互逆性质（AI中80%场景够用），换元性质重点理解“凑微分法”（适配激活函数、损失函数的积分计算）；\n",
    "4. **强化“验证思维”**：工程中通过互逆性质校验积分结果（求导验证），避免数值计算错误，这是AI模型概率正确性的关键保障；\n",
    "5. **衔接后续定积分知识**：不定积分是定积分（AI中概率计算、期望损失、面积积分）的基础，重点关注“不定积分→定积分”的桥梁（牛顿-莱布尼茨公式），为后续工程应用铺垫。\n",
    "\n",
    "是否需要我针对**不定积分与定积分的衔接（牛顿-莱布尼茨公式）** 或**AI中高频积分公式的推导与应用**，提供更详细的案例和工程代码？"
   ],
   "id": "4ceaf1af7f8020b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2f5b4893e6377009"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
